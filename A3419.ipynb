{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M1_Q-Q0aOmVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "783779db-facb-421f-f1a8-9e05ce297547"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndata = pd.read_csv(\"fer2013.csv\")\\n\\n#image 7\\nimage_row = data.iloc[7]\\n\\n#pixel values and reshape the image into a square\\npixels = image_row[\\'pixels\\'].split()\\nimage_array = np.array(pixels, dtype=\\'uint8\\').reshape((48, 48))\\n\\n#show image\\nplt.imshow(image_array, cmap=\\'gray\\')\\nplt.axis(\\'off\\')\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#https://www.kaggle.com/datasets/msambare/fer2013/data\n",
        "##https://medium.com/analytics-vidhya/implementing-svm-for-performing-classification-and-finding-accuracy-in-python-using-datasets-wine-e4fef8e804b4\n",
        "#https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262\n",
        "#https://medium.com/swlh/confusion-matrix-and-classification-report-88105288d48f\n",
        "#https://numpy.org/doc/stable/reference/generated/numpy.fromstring.html\n",
        "#https://neptune.ai/blog/how-to-use-google-colab-for-deep-learning-complete-tutorial\n",
        "#https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "#https://www.tensorflow.org/tutorials/images/cnn\n",
        "#https://stackoverflow.com/questions/53609697/keras-what-accuracy-metric-should-be-used-along-with-sparse-categorical-crosse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "'''\n",
        "data = pd.read_csv(\"fer2013.csv\")\n",
        "\n",
        "#image 7\n",
        "image_row = data.iloc[7]\n",
        "\n",
        "#pixel values and reshape the image into a square\n",
        "pixels = image_row['pixels'].split()\n",
        "image_array = np.array(pixels, dtype='uint8').reshape((48, 48))\n",
        "\n",
        "#show image\n",
        "plt.imshow(image_array, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PART A1\n",
        "#CSV file into DataFrame data\n",
        "data = pd.read_csv('fer2013.csv')\n",
        "\n",
        "#Splitting the DataFrame from \"Usage\" column\n",
        "train_data = data[data['Usage'] == 'Training']\n",
        "test_data = data[data['Usage'] == 'PrivateTest']\n",
        "\n",
        "#extracting the pixels and labels for training and test sets\n",
        "X_train = np.array([np.fromstring(pixel, dtype=int, sep=' ') for pixel in train_data['pixels']])\n",
        "y_train = train_data['emotion'].values\n",
        "\n",
        "X_test = np.array([np.fromstring(pixel, dtype=int, sep=' ') for pixel in test_data['pixels']])\n",
        "y_test = test_data['emotion'].values\n",
        "\n",
        "#SVM classifier\n",
        "svm_classifier = SVC()\n",
        "\n",
        "#raining the SVM classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "#test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "#evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "#evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WwQRN9pci4q",
        "outputId": "96317b49-15cc-479d-a781-db2d2ac2897b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4471997770966843\n",
            "Precision: 0.45357166337232335\n",
            "Recall: 0.4471997770966843\n",
            "F1 Score: 0.42950209418514934\n",
            "Confusion Matrix:\n",
            "[[109   0  46 142  96  20  78]\n",
            " [  7   3   3  24   6   2  10]\n",
            " [ 39   0 122 131 111  50  75]\n",
            " [ 25   0  30 636 101  18  69]\n",
            " [ 35   0  50 136 241  11 121]\n",
            " [ 13   0  40  68  31 219  45]\n",
            " [ 28   0  25 182 101  15 275]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PART B1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Splitting validation\n",
        "val_data = data[data['Usage'] == 'PublicTest']\n",
        "X_val = np.array([np.fromstring(pixel, dtype=int, sep=' ') for pixel in val_data['pixels']])\n",
        "\n",
        "y_train = to_categorical(train_data['emotion'], num_classes=7)\n",
        "y_val = to_categorical(val_data['emotion'], num_classes=7)\n",
        "y_test = test_data['emotion'].values\n",
        "\n",
        "#reshape the data into 48x48 grayscale images\n",
        "X_train = X_train.reshape(-1, 48, 48, 1)\n",
        "X_val = X_val.reshape(-1, 48, 48, 1)\n",
        "X_test = X_test.reshape(-1, 48, 48, 1)\n",
        "\n",
        "#normalize pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_val = X_val.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "#CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_val, y_val))\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "#evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTlbq44hmLpH",
        "outputId": "fee5b380-ddb5-477e-dc8b-8e3842bfd7a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "225/225 [==============================] - 113s 490ms/step - loss: 1.7676 - accuracy: 0.3473 - val_loss: 1.9504 - val_accuracy: 0.2003\n",
            "Epoch 2/30\n",
            "225/225 [==============================] - 118s 525ms/step - loss: 1.4309 - accuracy: 0.4500 - val_loss: 1.8987 - val_accuracy: 0.2421\n",
            "Epoch 3/30\n",
            "225/225 [==============================] - 106s 470ms/step - loss: 1.3053 - accuracy: 0.5040 - val_loss: 1.3224 - val_accuracy: 0.5029\n",
            "Epoch 4/30\n",
            "225/225 [==============================] - 116s 516ms/step - loss: 1.2138 - accuracy: 0.5404 - val_loss: 1.2323 - val_accuracy: 0.5322\n",
            "Epoch 5/30\n",
            "225/225 [==============================] - 110s 489ms/step - loss: 1.1377 - accuracy: 0.5669 - val_loss: 1.2022 - val_accuracy: 0.5497\n",
            "Epoch 6/30\n",
            "225/225 [==============================] - 120s 535ms/step - loss: 1.0577 - accuracy: 0.6026 - val_loss: 1.2804 - val_accuracy: 0.5252\n",
            "Epoch 7/30\n",
            "225/225 [==============================] - 106s 471ms/step - loss: 0.9926 - accuracy: 0.6237 - val_loss: 1.2243 - val_accuracy: 0.5380\n",
            "Epoch 8/30\n",
            "225/225 [==============================] - 104s 463ms/step - loss: 0.9241 - accuracy: 0.6452 - val_loss: 1.2166 - val_accuracy: 0.5626\n",
            "Epoch 9/30\n",
            "225/225 [==============================] - 111s 494ms/step - loss: 0.8494 - accuracy: 0.6791 - val_loss: 1.1880 - val_accuracy: 0.5798\n",
            "Epoch 10/30\n",
            "225/225 [==============================] - 106s 474ms/step - loss: 0.7885 - accuracy: 0.7020 - val_loss: 1.2987 - val_accuracy: 0.5469\n",
            "Epoch 11/30\n",
            "225/225 [==============================] - 104s 463ms/step - loss: 0.7266 - accuracy: 0.7249 - val_loss: 1.2856 - val_accuracy: 0.5759\n",
            "Epoch 12/30\n",
            "225/225 [==============================] - 108s 482ms/step - loss: 0.6619 - accuracy: 0.7505 - val_loss: 1.4246 - val_accuracy: 0.5673\n",
            "Epoch 13/30\n",
            "225/225 [==============================] - 107s 475ms/step - loss: 0.6120 - accuracy: 0.7695 - val_loss: 1.3496 - val_accuracy: 0.5784\n",
            "Epoch 14/30\n",
            "225/225 [==============================] - 106s 470ms/step - loss: 0.5624 - accuracy: 0.7882 - val_loss: 1.4535 - val_accuracy: 0.5762\n",
            "Epoch 15/30\n",
            "225/225 [==============================] - 108s 480ms/step - loss: 0.5172 - accuracy: 0.8028 - val_loss: 1.5125 - val_accuracy: 0.5723\n",
            "Epoch 16/30\n",
            "225/225 [==============================] - 108s 481ms/step - loss: 0.4674 - accuracy: 0.8226 - val_loss: 1.5847 - val_accuracy: 0.5798\n",
            "Epoch 17/30\n",
            "225/225 [==============================] - 103s 460ms/step - loss: 0.4478 - accuracy: 0.8306 - val_loss: 1.8534 - val_accuracy: 0.5511\n",
            "Epoch 18/30\n",
            "225/225 [==============================] - 104s 462ms/step - loss: 0.4196 - accuracy: 0.8410 - val_loss: 1.6860 - val_accuracy: 0.5809\n",
            "Epoch 19/30\n",
            "225/225 [==============================] - 106s 474ms/step - loss: 0.3785 - accuracy: 0.8554 - val_loss: 1.6729 - val_accuracy: 0.5737\n",
            "Epoch 20/30\n",
            "225/225 [==============================] - 105s 468ms/step - loss: 0.3612 - accuracy: 0.8638 - val_loss: 1.9097 - val_accuracy: 0.5673\n",
            "Epoch 21/30\n",
            "225/225 [==============================] - 102s 453ms/step - loss: 0.3372 - accuracy: 0.8744 - val_loss: 1.6800 - val_accuracy: 0.5639\n",
            "Epoch 22/30\n",
            "225/225 [==============================] - 108s 482ms/step - loss: 0.3276 - accuracy: 0.8768 - val_loss: 2.0651 - val_accuracy: 0.5743\n",
            "Epoch 23/30\n",
            "225/225 [==============================] - 106s 470ms/step - loss: 0.3167 - accuracy: 0.8812 - val_loss: 1.7555 - val_accuracy: 0.5422\n",
            "Epoch 24/30\n",
            "225/225 [==============================] - 103s 459ms/step - loss: 0.2935 - accuracy: 0.8912 - val_loss: 2.0485 - val_accuracy: 0.5712\n",
            "Epoch 25/30\n",
            "225/225 [==============================] - 106s 472ms/step - loss: 0.2846 - accuracy: 0.8928 - val_loss: 2.2470 - val_accuracy: 0.5865\n",
            "Epoch 26/30\n",
            "225/225 [==============================] - 110s 488ms/step - loss: 0.2736 - accuracy: 0.9006 - val_loss: 2.2229 - val_accuracy: 0.5687\n",
            "Epoch 27/30\n",
            "225/225 [==============================] - 105s 468ms/step - loss: 0.2664 - accuracy: 0.9023 - val_loss: 2.1781 - val_accuracy: 0.5695\n",
            "Epoch 28/30\n",
            "225/225 [==============================] - 111s 496ms/step - loss: 0.2539 - accuracy: 0.9041 - val_loss: 2.4280 - val_accuracy: 0.5715\n",
            "Epoch 29/30\n",
            "225/225 [==============================] - 111s 494ms/step - loss: 0.2483 - accuracy: 0.9067 - val_loss: 2.2312 - val_accuracy: 0.5676\n",
            "Epoch 30/30\n",
            "225/225 [==============================] - 109s 483ms/step - loss: 0.2325 - accuracy: 0.9138 - val_loss: 2.1545 - val_accuracy: 0.5690\n",
            "113/113 [==============================] - 3s 28ms/step\n",
            "Accuracy: 0.5711897464474784\n",
            "Precision: 0.5718433412785994\n",
            "Recall: 0.5711897464474784\n",
            "F1 Score: 0.5695922615028344\n",
            "Confusion Matrix:\n",
            "[[219   2  63  33  90  17  67]\n",
            " [ 16  20   5   2   5   0   7]\n",
            " [ 59   2 203  49 105  47  63]\n",
            " [ 31   0  28 693  53  13  61]\n",
            " [ 68   0  80  56 273  10 107]\n",
            " [ 15   0  40  34  18 297  12]\n",
            " [ 46   1  55  56 110  13 345]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PART A2\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# phoebe data\n",
        "data = pd.read_csv('phoebe_AU.csv')\n",
        "\n",
        "#Action Units\n",
        "X = data.drop(['file_name', 'label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "#convert 'unknown' label to a numerical value, for example, 0\n",
        "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
        "\n",
        "y = y.replace({'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'sad': 4, 'surprise': 5, 'unknown': 6})\n",
        "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
        "\n",
        "#5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracy_scores = cross_val_score(svm_model, X, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(\"Accuracy scores for 5-fold cross-validation:\")\n",
        "print(accuracy_scores)\n",
        "print(\"Mean accuracy:\", accuracy_scores.mean())\n",
        "\n",
        "#svm\n",
        "svm_model.fit(X, y)\n",
        "y_pred = svm_model.predict(X)\n",
        "\n",
        "#evaluation metrics\n",
        "conf_matrix = confusion_matrix(y, y_pred)\n",
        "classification_rep = classification_report(y, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9_8JACtuuaQ",
        "outputId": "af3c71e2-bdab-4591-8f80-9e98974d6cdf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy scores for 5-fold cross-validation:\n",
            "[0.3        0.35       0.3        0.31578947 0.31578947]\n",
            "Mean accuracy: 0.3163157894736842\n",
            "\n",
            "Confusion Matrix:\n",
            "[[11  0  0  0  0  0]\n",
            " [ 0  9  0  0  0  0]\n",
            " [ 0  0 33  0  0  0]\n",
            " [ 0  0  0 16  1  0]\n",
            " [ 0  0  0  0 16  0]\n",
            " [ 0  0  0  0  0 12]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00         9\n",
            "           3       1.00      1.00      1.00        33\n",
            "           4       1.00      0.94      0.97        17\n",
            "           5       0.94      1.00      0.97        16\n",
            "           6       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.99        98\n",
            "   macro avg       0.99      0.99      0.99        98\n",
            "weighted avg       0.99      0.99      0.99        98\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART B2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#Phoebe \"unknown\" images\n",
        "unknown_images_path = \"/content/drive/MyDrive/Colab Notebooks/images/unknown\"\n",
        "unknown_image_files = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/images/unknown\")\n",
        "\n",
        "#preprocess the images\n",
        "unknown_images = []\n",
        "for image_file in unknown_image_files:\n",
        "    img_path = os.path.join(unknown_images_path, image_file)\n",
        "    img = image.load_img(img_path, target_size=(48, 48), grayscale=True)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array /= 255.0  # Normalize pixel values\n",
        "    unknown_images.append(img_array)\n",
        "\n",
        "unknown_images = np.array(unknown_images)\n",
        "unknown_predictions = model.predict(unknown_images)\n",
        "emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
        "predicted_labels = [emotion_labels[np.argmax(prediction)] for prediction in unknown_predictions]\n",
        "\n",
        "#show labels\n",
        "for image_file, predicted_label in zip(unknown_image_files, predicted_labels):\n",
        "    print(f\"{image_file}: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7abTj_cCVQfy",
        "outputId": "3060f703-5831-4d2a-ac96-6ef76671806e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "41_06.jpg: happy\n",
            "1_01.jpg: angry\n",
            "48_01.jpg: happy\n",
            "46_03.jpg: happy\n",
            "35_42.jpg: sad\n",
            "8_01.jpg: happy\n",
            "4_01.jpg: sad\n",
            "4_20.jpg: sad\n",
            "9_41.jpg: happy\n",
            "26_123.jpg: happy\n",
            "44_01.jpg: neutral\n",
            "52_31.jpg: sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#Phoebe \"unknown\" images\n",
        "unknown_images_path = \"/content/drive/MyDrive/Colab Notebooks/images/unknown\"\n",
        "\n",
        "#CNN model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#trainin the model on Phoebe expressions image dataset\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(X_val, y_val))\n",
        "\n",
        "#loading Phoebe \"unknown\" images\n",
        "unknown_image_files = os.listdir(unknown_images_path)\n",
        "\n",
        "#preprocess the images\n",
        "unknown_images = []\n",
        "for image_file in unknown_image_files:\n",
        "    img_path = os.path.join(unknown_images_path, image_file)\n",
        "    img = image.load_img(img_path, target_size=(48, 48), grayscale=True)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array /= 255.0  # Normalize pixel values\n",
        "    unknown_images.append(img_array)\n",
        "\n",
        "unknown_images = np.array(unknown_images)\n",
        "\n",
        "#trained model\n",
        "unknown_predictions = model.predict(unknown_images)\n",
        "#emotion labels\n",
        "emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
        "predicted_labels = [emotion_labels[np.argmax(prediction)] for prediction in unknown_predictions]\n",
        "#predicted labels\n",
        "for image_file, predicted_label in zip(unknown_image_files, predicted_labels):\n",
        "    print(f\"{image_file}: {predicted_label}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXT7noBtWxCe",
        "outputId": "46bcec73-b661-4cc3-dd14-20e43e597ff2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "225/225 [==============================] - 118s 510ms/step - loss: 1.7517 - accuracy: 0.3526 - val_loss: 1.8985 - val_accuracy: 0.2533\n",
            "Epoch 2/30\n",
            "225/225 [==============================] - 135s 602ms/step - loss: 1.4348 - accuracy: 0.4531 - val_loss: 1.5511 - val_accuracy: 0.3826\n",
            "Epoch 3/30\n",
            "225/225 [==============================] - 116s 517ms/step - loss: 1.3059 - accuracy: 0.5075 - val_loss: 1.4830 - val_accuracy: 0.4430\n",
            "Epoch 4/30\n",
            "225/225 [==============================] - 121s 538ms/step - loss: 1.2085 - accuracy: 0.5456 - val_loss: 1.2536 - val_accuracy: 0.5291\n",
            "Epoch 5/30\n",
            "225/225 [==============================] - 132s 590ms/step - loss: 1.1351 - accuracy: 0.5732 - val_loss: 1.2739 - val_accuracy: 0.5263\n",
            "Epoch 6/30\n",
            "225/225 [==============================] - 127s 562ms/step - loss: 1.0579 - accuracy: 0.6021 - val_loss: 1.3311 - val_accuracy: 0.5127\n",
            "Epoch 7/30\n",
            "225/225 [==============================] - 137s 608ms/step - loss: 0.9822 - accuracy: 0.6292 - val_loss: 1.2252 - val_accuracy: 0.5536\n",
            "Epoch 8/30\n",
            "225/225 [==============================] - 105s 465ms/step - loss: 0.9070 - accuracy: 0.6576 - val_loss: 1.2215 - val_accuracy: 0.5587\n",
            "Epoch 9/30\n",
            "225/225 [==============================] - 108s 480ms/step - loss: 0.8435 - accuracy: 0.6852 - val_loss: 1.2714 - val_accuracy: 0.5659\n",
            "Epoch 10/30\n",
            "225/225 [==============================] - 150s 669ms/step - loss: 0.7703 - accuracy: 0.7122 - val_loss: 1.3295 - val_accuracy: 0.5623\n",
            "Epoch 11/30\n",
            "225/225 [==============================] - 107s 474ms/step - loss: 0.7156 - accuracy: 0.7317 - val_loss: 1.3124 - val_accuracy: 0.5653\n",
            "Epoch 12/30\n",
            "225/225 [==============================] - 107s 474ms/step - loss: 0.6542 - accuracy: 0.7529 - val_loss: 1.3359 - val_accuracy: 0.5645\n",
            "Epoch 13/30\n",
            "225/225 [==============================] - 104s 465ms/step - loss: 0.5947 - accuracy: 0.7751 - val_loss: 1.3815 - val_accuracy: 0.5818\n",
            "Epoch 14/30\n",
            "225/225 [==============================] - 119s 527ms/step - loss: 0.5537 - accuracy: 0.7899 - val_loss: 1.4006 - val_accuracy: 0.5589\n",
            "Epoch 15/30\n",
            "225/225 [==============================] - 133s 592ms/step - loss: 0.4955 - accuracy: 0.8134 - val_loss: 1.5269 - val_accuracy: 0.5717\n",
            "Epoch 16/30\n",
            "225/225 [==============================] - 104s 461ms/step - loss: 0.4720 - accuracy: 0.8224 - val_loss: 1.5916 - val_accuracy: 0.5793\n",
            "Epoch 17/30\n",
            "225/225 [==============================] - 110s 488ms/step - loss: 0.4430 - accuracy: 0.8322 - val_loss: 1.6897 - val_accuracy: 0.5612\n",
            "Epoch 18/30\n",
            "225/225 [==============================] - 109s 485ms/step - loss: 0.4149 - accuracy: 0.8445 - val_loss: 1.7337 - val_accuracy: 0.5587\n",
            "Epoch 19/30\n",
            "225/225 [==============================] - 103s 459ms/step - loss: 0.3880 - accuracy: 0.8561 - val_loss: 1.7986 - val_accuracy: 0.5623\n",
            "Epoch 20/30\n",
            "225/225 [==============================] - 109s 486ms/step - loss: 0.3689 - accuracy: 0.8611 - val_loss: 1.8509 - val_accuracy: 0.5729\n",
            "Epoch 21/30\n",
            "225/225 [==============================] - 102s 455ms/step - loss: 0.3426 - accuracy: 0.8723 - val_loss: 1.9448 - val_accuracy: 0.5517\n",
            "Epoch 22/30\n",
            "225/225 [==============================] - 105s 465ms/step - loss: 0.3201 - accuracy: 0.8792 - val_loss: 2.1366 - val_accuracy: 0.5589\n",
            "Epoch 23/30\n",
            "225/225 [==============================] - 111s 492ms/step - loss: 0.3117 - accuracy: 0.8855 - val_loss: 1.9542 - val_accuracy: 0.5715\n",
            "Epoch 24/30\n",
            "225/225 [==============================] - 103s 458ms/step - loss: 0.2992 - accuracy: 0.8891 - val_loss: 2.0331 - val_accuracy: 0.5497\n",
            "Epoch 25/30\n",
            "225/225 [==============================] - 108s 482ms/step - loss: 0.2838 - accuracy: 0.8937 - val_loss: 2.3479 - val_accuracy: 0.5659\n",
            "Epoch 26/30\n",
            "225/225 [==============================] - 105s 464ms/step - loss: 0.2662 - accuracy: 0.9004 - val_loss: 2.1422 - val_accuracy: 0.5754\n",
            "Epoch 27/30\n",
            "225/225 [==============================] - 105s 469ms/step - loss: 0.2675 - accuracy: 0.9006 - val_loss: 2.0651 - val_accuracy: 0.5595\n",
            "Epoch 28/30\n",
            "225/225 [==============================] - 105s 469ms/step - loss: 0.2481 - accuracy: 0.9073 - val_loss: 2.2129 - val_accuracy: 0.5670\n",
            "Epoch 29/30\n",
            "225/225 [==============================] - 103s 458ms/step - loss: 0.2378 - accuracy: 0.9110 - val_loss: 2.2619 - val_accuracy: 0.5862\n",
            "Epoch 30/30\n",
            "225/225 [==============================] - 108s 479ms/step - loss: 0.2323 - accuracy: 0.9125 - val_loss: 2.4303 - val_accuracy: 0.5692\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "41_06.jpg: happy\n",
            "1_01.jpg: sad\n",
            "48_01.jpg: happy\n",
            "46_03.jpg: happy\n",
            "35_42.jpg: sad\n",
            "8_01.jpg: happy\n",
            "4_01.jpg: sad\n",
            "4_20.jpg: neutral\n",
            "9_41.jpg: happy\n",
            "26_123.jpg: happy\n",
            "44_01.jpg: neutral\n",
            "52_31.jpg: sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "SVM-Fer2013 -Uses Fer2013 dataset with SVM\n",
        "SVM-OpenFace -Uses Phoebe AU.csv with SVM\n",
        "NN-Fer2013 -Uses Fer2013 dataset with Neural Network\n",
        "NN-FineTuned -Usies Fine-Tuned Neural Network on Phoebe-face images\n",
        "\n",
        "SVM-OpenFace worked best with this dataset image 4_20.jpg represents sad emotion expressions"
      ],
      "metadata": {
        "id": "y8ykodDDwth1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}